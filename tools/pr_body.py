"""Generate PR body for translation changes."""

import click
import json
from typing import Dict, List, Any
from pathlib import Path
from datetime import datetime
from config import config


class PRBodyGenerator:
    """Generate PR body for translation changes."""
    
    def __init__(self):
        """Initialize PR body generator."""
        pass
    
    def generate_pr_body(self, changes_file: str, apply_results_file: str = None, report_file: str = None) -> str:
        """Generate PR body from changes and results."""
        # Load changes
        with open(changes_file, 'r', encoding='utf-8') as f:
            changes = json.load(f)
        
        # Load apply results if available
        apply_results = None
        if apply_results_file and Path(apply_results_file).exists():
            with open(apply_results_file, 'r', encoding='utf-8') as f:
                apply_results = json.load(f)
        
        # Load report.json if available
        report_data = None
        if report_file and Path(report_file).exists():
            with open(report_file, 'r', encoding='utf-8') as f:
                report_data = json.load(f)
        
        # Generate PR body
        body_parts = []
        
        # Header
        body_parts.append("# ðŸ”„ LLM Translation Sync")
        body_parts.append("")
        body_parts.append(f"Automated translation sync from upstream at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        body_parts.append("")
        
        # Summary section
        body_parts.extend(self._generate_summary_section(changes, apply_results, report_data))
        
        # File changes section
        body_parts.extend(self._generate_file_changes_section(changes, report_data))
        
        # Links section
        body_parts.extend(self._generate_links_section(changes))
        
        # Verification section
        body_parts.extend(self._generate_verification_section(apply_results))
        
        # Footer
        body_parts.append("")
        body_parts.append("---")
        body_parts.append("*This PR was automatically generated by the LLM translation pipeline.*")
        
        return '\n'.join(body_parts)
    
    def _generate_summary_section(self, changes: Dict[str, Any], apply_results: Dict[str, Any] = None, report_data: Dict[str, Any] = None) -> List[str]:
        """Generate summary section."""
        lines = []
        lines.append("## ðŸ“Š Summary")
        lines.append("")
        
        # Count files by category
        file_counts = {}
        for category, files in changes["files"].items():
            file_counts[category] = len(files)
        
        lines.append(f"- **Translation targets**: {file_counts.get('translate', 0)} files")
        lines.append(f"- **Copy-only files**: {file_counts.get('copy_only', 0)} files")
        lines.append(f"- **Ignored files**: {file_counts.get('ignore', 0)} files")
        
        # Add report.json aggregated statistics if available
        if report_data and "summary" in report_data:
            lines.append("")
            lines.append("### ðŸ“ˆ Aggregated Statistics (from report.json)")
            summary = report_data["summary"]
            
            # File operations summary
            if "files" in summary:
                files_summary = summary["files"]
                lines.append(f"- **Inserted**: {files_summary.get('inserted', 0)} files")
                lines.append(f"- **Replaced**: {files_summary.get('replaced', 0)} files")  
                lines.append(f"- **Kept**: {files_summary.get('kept', 0)} files")
                lines.append(f"- **Deleted**: {files_summary.get('deleted', 0)} files")
                lines.append(f"- **Non-doc copied**: {files_summary.get('nondoc_copied', 0)} files")
            
            # Operations summary
            if "operations" in summary:
                ops_summary = summary["operations"]
                lines.append("")
                lines.append("**Operations:**")
                lines.append(f"- **LLM calls**: {ops_summary.get('llm_calls', 0)}")
                lines.append(f"- **Retries**: {ops_summary.get('retries', 0)}")
                lines.append(f"- **Cache hits**: {ops_summary.get('cache_hits', 0)}")
                lines.append(f"- **Processing time**: {ops_summary.get('total_processing_time', 0):.1f}s")
        
        if apply_results:
            stats = apply_results.get("statistics", {})
            lines.append("")
            lines.append("### ðŸ”„ Processing Results")
            if "files" in stats:
                files_stats = stats["files"]
                lines.append(f"- âœ… **Translated**: {files_stats.get('translated', 0)} files")
                lines.append(f"- ðŸ“‹ **Copied**: {files_stats.get('copied', 0)} files")
                lines.append(f"- â™»ï¸ **Kept existing**: {files_stats.get('kept_existing', 0)} files")
                lines.append(f"- âŒ **Errors**: {files_stats.get('errors', 0)} files")
            else:
                # Fallback to old format
                lines.append(f"- âœ… **Translated**: {stats.get('translated', 0)} files")
                lines.append(f"- ðŸ“‹ **Copied**: {stats.get('copied', 0)} files")
                lines.append(f"- â™»ï¸ **Kept existing**: {stats.get('kept_existing', 0)} files")
                lines.append(f"- âŒ **Errors**: {len(apply_results.get('errors', []))} files")
        
        lines.append("")
        return lines
    
    def _generate_file_changes_section(self, changes: Dict[str, Any], report_data: Dict[str, Any] = None) -> List[str]:
        """Generate detailed file changes section."""
        lines = []
        lines.append("## ðŸ“‹ File Changes")
        lines.append("")
        
        # Enhanced translation files table with all required information
        translate_files = changes["files"].get("translate", [])
        if translate_files:
            lines.append("### ðŸŒ Translation Files")
            lines.append("")
            lines.append("| File | Status | Strategy | Lines Diff | SHA | Commit |")
            lines.append("|------|--------|----------|------------|-----|--------|")
            
            for file_info in translate_files:
                path = file_info["path"]
                status = file_info.get("status", "unknown")
                strategy = file_info.get("strategy", "unknown")
                
                # Calculate line diff
                lines_before = file_info.get("total_lines_before", 0)
                lines_after = file_info.get("total_lines_after", 0)
                added = file_info.get("lines_added", 0)
                removed = file_info.get("lines_removed", 0)
                line_diff = f"+{added}/-{removed} ({lines_before}â†’{lines_after})"
                
                # SHA and commit link
                sha = file_info.get("upstream_sha", "unknown")[:8]
                commit_url = file_info.get("upstream_commit_url", "")
                commit_link = f"[{sha}]({commit_url})" if commit_url else sha
                
                lines.append(f"| `{path}` | {status} | {strategy} | {line_diff} | {sha} | {commit_link} |")
            
            lines.append("")
        
        # Enhanced copy-only files section
        copy_files = changes["files"].get("copy_only", [])
        if copy_files:
            lines.append("### ðŸ“„ Copy-Only Files")
            lines.append("")
            lines.append("| File | Status | SHA | Commit |")
            lines.append("|------|--------|-----|--------|")
            
            for file_info in copy_files:
                path = file_info["path"]
                status = file_info.get("status", "unknown")
                sha = file_info.get("upstream_sha", "unknown")[:8]
                commit_url = file_info.get("upstream_commit_url", "")
                commit_link = f"[{sha}]({commit_url})" if commit_url else sha
                
                lines.append(f"| `{path}` | {status} | {sha} | {commit_link} |")
            
            lines.append("")
        
        # Deleted files section (if any)
        deleted_files = [f for f in translate_files if f.get("status") == "deleted"]
        if deleted_files:
            lines.append("### ðŸ—‘ï¸ Deleted Files")
            lines.append("")
            for file_info in deleted_files:
                path = file_info["path"]
                sha = file_info.get("upstream_sha", "unknown")[:8]
                commit_url = file_info.get("upstream_commit_url", "")
                commit_link = f"[{sha}]({commit_url})" if commit_url else sha
                lines.append(f"- `{path}` (deleted in {commit_link})")
            lines.append("")
        
        return lines
    
    def _generate_links_section(self, changes: Dict[str, Any]) -> List[str]:
        """Generate links section for review."""
        lines = []
        lines.append("## ðŸ”— Review Links")
        lines.append("")
        
        upstream_ref = changes.get("upstream_ref", "upstream/main")
        upstream_repo = config.upstream_repo
        origin_repo = config.origin_repo
        
        lines.append(f"### Upstream Changes")
        lines.append(f"- [View upstream commits](https://github.com/{upstream_repo}/commits/{upstream_ref.replace('upstream/', '')})")
        lines.append(f"- [Compare with upstream](https://github.com/{upstream_repo}/compare/{upstream_ref.replace('upstream/', '')})")
        lines.append("")
        
        lines.append(f"### Translation Branch")
        lines.append(f"- [View this PR's changes](https://github.com/{origin_repo}/pulls)")
        lines.append(f"- [Repository comparison](https://github.com/{origin_repo}/compare)")
        lines.append("")
        
        return lines
    
    def _generate_verification_section(self, apply_results: Dict[str, Any] = None) -> List[str]:
        """Generate verification section."""
        lines = []
        lines.append("## âœ… Verification")
        lines.append("")
        
        if apply_results:
            errors = apply_results.get("errors", [])
            if errors:
                lines.append("### âš ï¸ Errors")
                lines.append("")
                for error in errors:
                    lines.append(f"- `{error['file']}`: {error['error']}")
                lines.append("")
            else:
                lines.append("âœ… All files processed successfully without errors.")
                lines.append("")
        
        lines.append("### Manual Review Checklist")
        lines.append("")
        lines.append("- [ ] Translation quality looks appropriate")
        lines.append("- [ ] Line counts match between original and translated files")
        lines.append("- [ ] Code blocks and technical terms are preserved")
        lines.append("- [ ] Links and references are working")
        lines.append("- [ ] File structure matches upstream")
        lines.append("")
        
        return lines


@click.command()
@click.option('--changes-file', '-c', required=True, help='Changes file from discover_changes')
@click.option('--apply-results', '-r', help='Apply results file from apply_changes')
@click.option('--report-file', help='Report.json file for aggregated statistics')
@click.option('--output', '-o', help='Output file for PR body (default: .out/pr_body.md)')
@click.option('--template', help='Custom template file for PR body')
@click.help_option('--help', '-h')
def main(changes_file: str, apply_results: str, report_file: str, output: str, template: str):
    """Generate PR body for translation changes.
    
    This tool generates a comprehensive PR description including file changes,
    statistics, review links, and verification checklists.
    
    Examples:
        python pr_body.py -c .out/changes.json
        python pr_body.py -c changes.json -r apply_results.json
        python pr_body.py -c changes.json --report-file report.json
        python pr_body.py -c changes.json -r apply_results.json --report-file report.json -o my_pr_body.md
    """
    
    try:
        # Validate inputs
        changes_path = Path(changes_file)
        if not changes_path.exists():
            click.echo(f"Error: Changes file '{changes_file}' not found", err=True)
            return 1
        
        if not output:
            output = str(config.output_dir / "pr_body.md")
        
        click.echo(f"Generating PR body from: {changes_file}")
        if apply_results:
            click.echo(f"Including apply results from: {apply_results}")
        if report_file:
            click.echo(f"Including report data from: {report_file}")
        
        # Generate PR body
        generator = PRBodyGenerator()
        pr_body = generator.generate_pr_body(changes_file, apply_results, report_file)
        
        # Write output
        output_path = Path(output)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(pr_body)
        
        click.echo(f"PR body generated successfully!")
        click.echo(f"Output written to: {output}")
        
        # Preview
        click.echo(f"\n=== PR Body Preview ===")
        lines = pr_body.split('\n')
        for line in lines[:20]:  # Show first 20 lines
            click.echo(line)
        
        if len(lines) > 20:
            click.echo(f"... ({len(lines) - 20} more lines)")
        
        return 0
        
    except Exception as e:
        click.echo(f"Error generating PR body: {e}", err=True)
        return 1


if __name__ == '__main__':
    exit(main())