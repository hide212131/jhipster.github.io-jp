#!/usr/bin/env python3
"""
å·®åˆ†æ¤œå‡ºãƒ»é©ç”¨ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
å®Œå…¨ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®ä¾‹
"""

import tempfile
import os
from pathlib import Path
import sys

# tools ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from discover_changes import DiffDiscoverer, serialize_operations
from apply_changes import ChangeApplier


def create_demo_files():
    """ãƒ‡ãƒ¢ç”¨ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ"""
    # è‹±èªžåŽŸæ–‡ (upstream)
    english_content = """# JHipster Getting Started Guide

## Introduction
Welcome to JHipster! This guide will help you get started.

## Prerequisites
Before you begin, make sure you have:
- Java 11 or higher
- Node.js 14 or higher
- Git

## Installation Steps
1. Install JHipster CLI
2. Create a new application
3. Configure your database
4. Run the application

## Next Steps
Explore the generated code and customize your application.
"""

    # æ—¥æœ¬èªžè¨³ (æ—¢å­˜)
    japanese_content = """# JHipster ã‚¹ã‚¿ãƒ¼ãƒˆã‚¬ã‚¤ãƒ‰

## ã¯ã˜ã‚ã«
JHipsterã¸ã‚ˆã†ã“ãï¼ã“ã®ã‚¬ã‚¤ãƒ‰ã§ã¯é–‹å§‹æ–¹æ³•ã‚’èª¬æ˜Žã—ã¾ã™ã€‚

## å‰ææ¡ä»¶
å§‹ã‚ã‚‹å‰ã«ã€ä»¥ä¸‹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ï¼š
- Java 8ä»¥ä¸Š
- Node.js 12ä»¥ä¸Š
- Git

## ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ‰‹é †
1. JHipster CLIã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
2. æ–°ã—ã„ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ä½œæˆ
3. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’è¨­å®š
4. ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œ

## æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—
ç”Ÿæˆã•ã‚ŒãŸã‚³ãƒ¼ãƒ‰ã‚’æŽ¢ç´¢ã—ã€ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ã‚«ã‚¹ã‚¿ãƒžã‚¤ã‚ºã—ã¦ãã ã•ã„ã€‚
"""

    return english_content.strip().split('\n'), japanese_content.strip().split('\n')


def demo_workflow():
    """å®Œå…¨ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®ãƒ‡ãƒ¢"""
    print("=" * 60)
    print("JHipsterå·®åˆ†æ¤œå‡ºãƒ»é©ç”¨ã‚·ã‚¹ãƒ†ãƒ  ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³")
    print("=" * 60)
    
    # ãƒ†ãƒ³ãƒãƒ©ãƒªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
    with tempfile.TemporaryDirectory(prefix="jhipster_diff_demo_") as temp_dir:
        temp_path = Path(temp_dir)
        
        # ãƒ‡ãƒ¢ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
        english_lines, japanese_lines = create_demo_files()
        
        english_file = temp_path / "english.md"
        japanese_file = temp_path / "japanese.md"
        diff_file = temp_path / "diff.json"
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã¿
        with open(english_file, 'w', encoding='utf-8') as f:
            f.write('\n'.join(english_lines) + '\n')
        
        with open(japanese_file, 'w', encoding='utf-8') as f:
            f.write('\n'.join(japanese_lines) + '\n')
        
        print(f"\nðŸ“ ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {temp_dir}")
        print(f"   è‹±èªžåŽŸæ–‡: {english_file.name}")
        print(f"   æ—¥æœ¬èªžè¨³: {japanese_file.name}")
        
        # Step 1: å·®åˆ†æ¤œå‡º
        print("\nðŸ” Step 1: å·®åˆ†æ¤œå‡º")
        discoverer = DiffDiscoverer()
        operations = discoverer.discover_from_files(str(english_file), str(japanese_file))
        
        # çµæžœã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        operations_json = serialize_operations(operations)
        with open(diff_file, 'w', encoding='utf-8') as f:
            f.write(operations_json)
        
        # çµ±è¨ˆã‚’è¡¨ç¤º
        total_ops = len(operations)
        by_opcode = {}
        minor_count = 0
        semantic_count = 0
        
        for op in operations:
            by_opcode[op.opcode] = by_opcode.get(op.opcode, 0) + 1
            if op.is_minor_change:
                minor_count += 1
            if op.has_semantic_change:
                semantic_count += 1
        
        print(f"   æ¤œå‡ºã•ã‚ŒãŸæ“ä½œæ•°: {total_ops}")
        print(f"   æ“ä½œåˆ¥å†…è¨³: {by_opcode}")
        print(f"   è»½å¾®å¤‰æ›´: {minor_count}")
        print(f"   æ„å‘³å¤‰åŒ–: {semantic_count}")
        
        # ä¸»è¦ãªå·®åˆ†ã‚’è¡¨ç¤º
        print("\nðŸ“‹ ä¸»è¦ãªå·®åˆ†:")
        for i, op in enumerate(operations[:5]):  # æœ€åˆã®5ã¤ã‚’è¡¨ç¤º
            if op.opcode != 'equal':
                print(f"   {i+1}. {op.opcode}: '{op.target_text[:30]}...' -> '{op.source_text[:30]}...'")
                if op.is_minor_change:
                    print(f"      (è»½å¾®å¤‰æ›´)")
                if op.has_semantic_change:
                    print(f"      (æ„å‘³å¤‰åŒ–ã‚ã‚Š)")
        
        # Step 2: å·®åˆ†é©ç”¨
        print(f"\nâœ… Step 2: å·®åˆ†é©ç”¨")
        applier = ChangeApplier(create_backup=True)
        
        # é©ç”¨å‰ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º
        original_size = japanese_file.stat().st_size
        
        # å·®åˆ†ã‚’é©ç”¨
        success = applier.apply_from_files(str(japanese_file), str(diff_file))
        
        if success:
            # é©ç”¨å¾Œã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º
            new_size = japanese_file.stat().st_size
            print(f"   å·®åˆ†é©ç”¨å®Œäº†ï¼")
            print(f"   ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {original_size} â†’ {new_size} bytes")
            
            # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
            backup_file = Path(str(japanese_file) + '.backup')
            if backup_file.exists():
                print(f"   ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ: {backup_file.name}")
        
        # Step 3: çµæžœæ¤œè¨¼
        print(f"\nðŸ”Ž Step 3: çµæžœæ¤œè¨¼")
        
        # é©ç”¨å¾Œã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
        with open(japanese_file, 'r', encoding='utf-8') as f:
            result_lines = [line.rstrip('\n\r') for line in f.readlines()]
        
        # è‹±èªžåŽŸæ–‡ã¨æ¯”è¼ƒ
        if result_lines == english_lines:
            print("   âœ… å®Œå…¨ä¸€è‡´: æ—¥æœ¬èªžãƒ•ã‚¡ã‚¤ãƒ«ãŒè‹±èªžåŽŸæ–‡ã¨åŒã˜å†…å®¹ã«ãªã‚Šã¾ã—ãŸ")
        else:
            print("   âš ï¸  å·®åˆ†ãŒæ®‹ã£ã¦ã„ã¾ã™")
            # ç°¡å˜ãªå·®åˆ†è¡¨ç¤º
            for i, (eng, jpn) in enumerate(zip(english_lines, result_lines)):
                if eng != jpn:
                    print(f"   è¡Œ{i+1}: '{jpn}' != '{eng}'")
                    break
        
        print(f"\nðŸ“Š å‡¦ç†ã‚µãƒžãƒªãƒ¼:")
        print(f"   - å‡¦ç†ã—ãŸæ“ä½œæ•°: {total_ops}")
        print(f"   - æ„å‘³å¤‰åŒ–ã®ã‚ã‚‹å¤‰æ›´: {semantic_count}")
        print(f"   - è»½å¾®å¤‰æ›´: {minor_count}")
        print(f"   - å·®åˆ†ãƒ•ã‚¡ã‚¤ãƒ«: {diff_file.name}")
        print(f"   - ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«: {japanese_file.name}.backup")
        
        print(f"\nðŸ’¡ å®Ÿéš›ã®é‹ç”¨ã§ã¯:")
        print(f"   1. --skip-minor ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§è»½å¾®å¤‰æ›´ã‚’ã‚¹ã‚­ãƒƒãƒ—")
        print(f"   2. --skip-no-semantic ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§æ„å‘³å¤‰åŒ–ã®ãªã„å¤‰æ›´ã‚’ã‚¹ã‚­ãƒƒãƒ—")
        print(f"   3. GEMINI_API_KEY ç’°å¢ƒå¤‰æ•°ã§AIæ„å‘³åˆ¤å®šã‚’æœ‰åŠ¹åŒ–")
        
        # ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã®ä¸€éƒ¨ã‚’è¡¨ç¤º
        print(f"\nðŸ“„ é©ç”¨å¾Œã®ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ (æœ€åˆã®5è¡Œ):")
        with open(japanese_file, 'r', encoding='utf-8') as f:
            for i, line in enumerate(f):
                if i >= 5:
                    break
                print(f"   {i+1}: {line.rstrip()}")
        
        print("\n" + "=" * 60)
        print("ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Œäº†!")
        print("=" * 60)


if __name__ == '__main__':
    demo_workflow()