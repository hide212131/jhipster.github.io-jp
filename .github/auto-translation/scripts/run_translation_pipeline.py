#!/usr/bin/env python3
"""
JHipsteræ—¥æœ¬èªãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆè‡ªå‹•ç¿»è¨³ã‚·ã‚¹ãƒ†ãƒ 
çµ±åˆç¿»è¨³ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import argparse
import json
import os
import subprocess
import sys
import time
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional


class TranslationPipeline:
    def __init__(self, commit_hash: str, dry_run: bool = False, mode: str = "normal",
                 before_commit: Optional[str] = None, limit: Optional[int] = None, 
                 paths: Optional[List[str]] = None):
        self.commit_hash = commit_hash
        self.dry_run = dry_run
        self.mode = mode
        self.before_commit = before_commit
        self.limit = limit
        self.paths = paths if paths else []
        self.start_time = datetime.now()
        self.script_dir = Path(__file__).parent
        self.classification_file = self.script_dir.parent / "classification.json"
        
        print(f"ğŸš€ Translation Pipeline Starting")
        print(f"   Target commit: {commit_hash}")
        print(f"   Mode: {mode}")
        print(f"   Dry run: {dry_run}")
        if mode == "dev":
            if before_commit:
                print(f"   Before commit: {before_commit}")
            if limit:
                print(f"   File limit: {limit}")
            if paths:
                print(f"   Target paths: {', '.join(paths)}")
        print(f"   Start time: {self.start_time.strftime('%Y-%m-%d %H:%M:%S')}")
        print()

    def run_step(self, step_name: str, command: List[str], required: bool = True, 
                 env_vars: Optional[Dict[str, str]] = None) -> bool:
        """ã‚¹ãƒ†ãƒƒãƒ—ã‚’å®Ÿè¡Œ"""
        print(f"ğŸ”„ Step: {step_name}")
        print(f"   Command: {' '.join(command)}")
        
        if self.dry_run and step_name not in ["Fetch upstream", "Classify changes"]:
            print(f"   â­ï¸  Skipped (dry run)")
            return True
        
        try:
            # ç’°å¢ƒå¤‰æ•°ã‚’è¨­å®š
            env = os.environ.copy()
            if env_vars:
                env.update(env_vars)
            if self.dry_run:
                env["DRY_RUN"] = "true"
            
            start_time = time.time()
            result = subprocess.run(
                command, 
                check=True, 
                capture_output=True, 
                text=True,
                env=env,
                cwd=self.script_dir.parent
            )
            duration = time.time() - start_time
            
            print(f"   âœ… Completed in {duration:.1f}s")
            
            # å‡ºåŠ›ãŒã‚ã‚‹å ´åˆã¯è¡¨ç¤ºï¼ˆæœ€å¾Œã®æ•°è¡Œã®ã¿ï¼‰
            if result.stdout.strip():
                output_lines = result.stdout.strip().split('\n')
                if len(output_lines) > 5:
                    print(f"   Output (last 5 lines):")
                    for line in output_lines[-5:]:
                        print(f"      {line}")
                else:
                    print(f"   Output:")
                    for line in output_lines:
                        print(f"      {line}")
            
            print()
            return True
            
        except subprocess.CalledProcessError as e:
            duration = time.time() - start_time
            print(f"   âŒ Failed in {duration:.1f}s")
            print(f"   Error: {e}")
            
            if e.stdout:
                print(f"   Stdout: {e.stdout}")
            if e.stderr:
                print(f"   Stderr: {e.stderr}")
                
            print()
            
            if required:
                print(f"ğŸ’¥ Pipeline failed at step: {step_name}")
                self.print_summary(success=False)
                sys.exit(1)
            return False

    def check_prerequisites(self) -> bool:
        """å‰ææ¡ä»¶ã‚’ãƒã‚§ãƒƒã‚¯"""
        print("ğŸ” Checking prerequisites...")
        
        # API keys check
        api_key = os.getenv("GEMINI_API_KEY")
        if not api_key or api_key == "fake_api_key_for_development":
            print("   âš ï¸  GEMINI_API_KEY not set or is placeholder")
            if not self.dry_run:
                print("   âŒ GEMINI_API_KEY is required for translation")
                return False
        else:
            print("   âœ… GEMINI_API_KEY is set")
        
        # Git config check
        try:
            subprocess.run(["git", "config", "user.name"], check=True, capture_output=True)
            subprocess.run(["git", "config", "user.email"], check=True, capture_output=True)
            print("   âœ… Git config is set")
        except subprocess.CalledProcessError:
            print("   âš ï¸  Git config not set (will be configured automatically)")
        
        # GitHub CLI check for PR creation
        if not self.dry_run:
            try:
                subprocess.run(["gh", "auth", "status"], check=True, capture_output=True)
                print("   âœ… GitHub CLI is authenticated")
            except (subprocess.CalledProcessError, FileNotFoundError):
                gh_token = os.getenv("GH_TOKEN") or os.getenv("GITHUB_TOKEN")
                if gh_token:
                    print("   âœ… GitHub token is available")
                else:
                    print("   âš ï¸  GitHub CLI not authenticated and no token found")
        
        print()
        return True

    def load_classification(self) -> Optional[Dict]:
        """åˆ†é¡çµæœã‚’èª­ã¿è¾¼ã¿"""
        try:
            if self.classification_file.exists():
                with open(self.classification_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
        except Exception as e:
            print(f"âš ï¸  Failed to load classification: {e}")
        return None

    def print_classification_summary(self, classification: Dict) -> None:
        """åˆ†é¡çµæœã®è¦ç´„ã‚’è¡¨ç¤º"""
        summary = classification.get("summary", {})
        total_files = classification.get("total_files", 0)
        translatable_files = classification.get("translatable_files", 0)
        
        print("ğŸ“‹ Classification Summary:")
        print(f"   Total files: {total_files}")
        print(f"   Translatable files: {translatable_files}")
        
        for category, files in summary.items():
            if files:
                category_names = {
                    "a": "ğŸ†• New documents",
                    "b-1": "âœï¸  Updated (no conflicts)",
                    "b-2": "âš ï¸  Updated (with conflicts)",
                    "c": "ğŸ“„ Non-translatable"
                }
                name = category_names.get(category, category)
                print(f"   {name}: {len(files)} files")
                
                # æœ€åˆã®3ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿è¡¨ç¤º
                for file in files[:3]:
                    print(f"      - {file}")
                if len(files) > 3:
                    print(f"      ... and {len(files) - 3} more")
        print()

    def print_summary(self, success: bool = True) -> None:
        """å®Ÿè¡Œçµæœã®è¦ç´„ã‚’è¡¨ç¤º"""
        duration = datetime.now() - self.start_time
        status = "âœ… COMPLETED" if success else "âŒ FAILED"
        
        print("=" * 60)
        print(f"ğŸ¯ Translation Pipeline {status}")
        print(f"   Target commit: {self.commit_hash}")
        print(f"   Mode: {self.mode}")
        print(f"   Duration: {duration.total_seconds():.1f}s")
        print(f"   Dry run: {self.dry_run}")
        
        # é–‹ç™ºãƒ¢ãƒ¼ãƒ‰ã®è¨­å®šã‚’è¡¨ç¤º
        if self.mode == "dev":
            if self.before_commit:
                print(f"   Before commit: {self.before_commit}")
            if self.limit:
                print(f"   File limit: {self.limit}")
            if self.paths:
                print(f"   Target paths: {', '.join(self.paths)}")
        
        # åˆ†é¡çµæœãŒã‚ã‚Œã°è¡¨ç¤º
        classification = self.load_classification()
        if classification:
            translatable_files = classification.get("translatable_files", 0)
            print(f"   Translatable files: {translatable_files}")
        
        print("=" * 60)

    def apply_dev_mode_filters(self, classification: Dict) -> Dict:
        """é–‹ç™ºãƒ¢ãƒ¼ãƒ‰ç”¨ã®ãƒ•ã‚£ãƒ«ã‚¿ã‚’é©ç”¨"""
        if self.mode != "dev":
            return classification
            
        print("ğŸ”§ Applying dev mode filters...")
        
        # ãƒ•ã‚£ãƒ«ã‚¿å‰ã®çŠ¶æ…‹ã‚’è¨˜éŒ²
        original_counts = {}
        for category in ["a", "b-1", "b-2", "c"]:
            original_counts[category] = len(classification.get("summary", {}).get(category, []))
        
        # before_commitãƒ•ã‚£ãƒ«ã‚¿: æŒ‡å®šã‚³ãƒŸãƒƒãƒˆä»¥å‰ã®å¤‰æ›´ã®ã¿å¯¾è±¡
        if self.before_commit:
            print(f"   ğŸ“… Filtering files modified before commit: {self.before_commit}")
            classification = self._filter_by_before_commit(classification)
        
        # pathsãƒ•ã‚£ãƒ«ã‚¿: ç‰¹å®šãƒ‘ã‚¹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿å¯¾è±¡
        if self.paths:
            print(f"   ğŸ“ Filtering by paths: {', '.join(self.paths)}")
            classification = self._filter_by_paths(classification)
        
        # limitãƒ•ã‚£ãƒ«ã‚¿: å‡¦ç†ãƒ•ã‚¡ã‚¤ãƒ«æ•°åˆ¶é™
        if self.limit:
            print(f"   ğŸ”¢ Limiting to {self.limit} files")
            classification = self._filter_by_limit(classification)
            
        # ãƒ•ã‚£ãƒ«ã‚¿å¾Œã®çŠ¶æ…‹ã‚’è¡¨ç¤º
        filtered_counts = {}
        for category in ["a", "b-1", "b-2", "c"]:
            filtered_counts[category] = len(classification.get("summary", {}).get(category, []))
            
        print("   ğŸ“Š Filter results:")
        for category in ["a", "b-1", "b-2", "c"]:
            orig = original_counts[category]
            filt = filtered_counts[category]
            if orig != filt:
                print(f"      Category {category}: {orig} â†’ {filt} files")
        
        # ç¿»è¨³å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«æ•°ã‚’å†è¨ˆç®—
        translatable_files = sum(len(files) for cat, files in classification.get("summary", {}).items() 
                                if cat in ["a", "b-1", "b-2"])
        classification["translatable_files"] = translatable_files
        
        print()
        return classification

    def check_sync_branch_exists(self) -> bool:
        """æŒ‡å®šã‚³ãƒŸãƒƒãƒˆä»¥å‰ã®å¤‰æ›´ã®ã¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿"""
        try:
            # before_commitã‚ˆã‚Šæ–°ã—ã„ã‚³ãƒŸãƒƒãƒˆã§ã®å¤‰æ›´ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é™¤å¤–
            result = subprocess.run(
                ["git", "diff", "--name-only", f"{self.before_commit}..HEAD"],
                capture_output=True, text=True, check=True,
                cwd=self.script_dir.parent.parent.parent
            )
            newer_files = set(result.stdout.strip().split('\n')) if result.stdout.strip() else set()
            
            # å„ã‚«ãƒ†ã‚´ãƒªã‹ã‚‰æ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é™¤å¤–
            summary = classification.get("summary", {})
            for category in ["a", "b-1", "b-2", "c"]:
                if category in summary:
                    summary[category] = [f for f in summary[category] if f not in newer_files]
                    
        except subprocess.CalledProcessError as e:
            print(f"      âš ï¸  Warning: Could not filter by before_commit: {e}")
        
        return classification
        
    def _filter_by_paths(self, classification: Dict) -> Dict:
        """æŒ‡å®šãƒ‘ã‚¹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿"""
        summary = classification.get("summary", {})
        for category in ["a", "b-1", "b-2", "c"]:
            if category in summary:
                summary[category] = [
                    f for f in summary[category] 
                    if any(f.startswith(path) for path in self.paths)
                ]
        return classification
        
    def _filter_by_limit(self, classification: Dict) -> Dict:
        """å‡¦ç†ãƒ•ã‚¡ã‚¤ãƒ«æ•°ã‚’åˆ¶é™"""
        summary = classification.get("summary", {})
        
        # ç¿»è¨³å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å„ªå…ˆé †ä½ã§åé›†ï¼ˆa > b-1 > b-2ï¼‰
        all_translatable = []
        for category in ["a", "b-1", "b-2"]:
            if category in summary:
                for file in summary[category]:
                    all_translatable.append((category, file))
        
        # åˆ¶é™æ•°ã¾ã§åˆ‡ã‚Šå–ã‚Š
        if len(all_translatable) > self.limit:
            limited_files = all_translatable[:self.limit]
            
            # å„ã‚«ãƒ†ã‚´ãƒªã‚’æ›´æ–°
            new_summary = {"a": [], "b-1": [], "b-2": [], "c": summary.get("c", [])}
            for category, file in limited_files:
                new_summary[category].append(file)
            summary.update(new_summary)
            
        return classification
        """syncãƒ–ãƒ©ãƒ³ãƒãŒæ—¢ã«å­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯"""
        # å®Œå…¨ãƒãƒƒã‚·ãƒ¥ã¨çŸ­ç¸®ãƒãƒƒã‚·ãƒ¥ã®ä¸¡æ–¹ã‚’ãƒã‚§ãƒƒã‚¯
        sync_branches = [
            f"sync-{self.commit_hash}",  # å®Œå…¨ç‰ˆ
            f"sync-{self.commit_hash[:7]}"  # çŸ­ç¸®ç‰ˆ
        ]
        
        try:
            result = subprocess.run(
                ["git", "branch", "--list"],
                capture_output=True, text=True, check=True
            )
            existing_branches = [line.strip().lstrip('* ') for line in result.stdout.split('\n') if line.strip()]
            
            for sync_branch in sync_branches:
                if sync_branch in existing_branches:
                    print(f"   Found existing sync branch: {sync_branch}")
                    return True
            return False
        except:
            return False

    def cleanup_previous_state(self) -> None:
        """å‰å›å®Ÿè¡Œã®æ®‹å­˜çŠ¶æ…‹ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        print("ğŸ§¹ Cleaning up previous state...")
        
        # å¤ã„classification.jsonã‚’å‰Šé™¤
        if self.classification_file.exists():
            try:
                self.classification_file.unlink()
                print(f"   âœ… Removed old classification file: {self.classification_file}")
            except Exception as e:
                print(f"   âš ï¸  Failed to remove classification file: {e}")
        
        print()

    def run(self) -> bool:
        """ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å…¨ä½“ã‚’å®Ÿè¡Œ"""
        try:
            # syncãƒ–ãƒ©ãƒ³ãƒãŒæ—¢ã«å­˜åœ¨ã™ã‚‹å ´åˆã¯çµ‚äº†
            if self.check_sync_branch_exists():
                print(f"â­ï¸  Sync branch for commit {self.commit_hash} already exists, skipping pipeline execution")
                print(f"   If you want to re-run, delete the existing sync branch first:")
                print(f"   git branch -D sync-{self.commit_hash[:7]}  # or sync-{self.commit_hash}")
                print()
                self.print_summary(success=True)
                return True
            
            # å‰å›å®Ÿè¡Œã®æ®‹å­˜çŠ¶æ…‹ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            self.cleanup_previous_state()
            
            # å‰ææ¡ä»¶ãƒã‚§ãƒƒã‚¯
            if not self.check_prerequisites():
                return False
            
            # Step 1: Fetch upstream changes
            success = self.run_step(
                "Fetch upstream", 
                ["python", "scripts/fetch_upstream.py", "--hash", self.commit_hash]
            )
            if not success:
                return False
            
            # Step 2: Classify changes
            success = self.run_step(
                "Classify changes",
                ["python", "scripts/classify_changes.py"]
            )
            if not success:
                return False
            
            # åˆ†é¡çµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            self.run_step(
                "Save classification",
                ["sh", "-c", "python scripts/classify_changes.py > classification.json"],
                required=True
            )
            
            # åˆ†é¡çµæœã‚’èª­ã¿è¾¼ã¿ã€ç¿»è¨³ãŒå¿…è¦ã‹ãƒã‚§ãƒƒã‚¯
            classification = self.load_classification()
            if not classification:
                print("âš ï¸  Could not load classification results")
                return False
            
            # é–‹ç™ºãƒ¢ãƒ¼ãƒ‰ã®ãƒ•ã‚£ãƒ«ã‚¿ã‚’é©ç”¨
            classification = self.apply_dev_mode_filters(classification)
            
            # ãƒ•ã‚£ãƒ«ã‚¿é©ç”¨å¾Œã®åˆ†é¡çµæœã‚’ä¿å­˜
            if self.mode == "dev":
                try:
                    with open(self.classification_file, 'w', encoding='utf-8') as f:
                        json.dump(classification, f, ensure_ascii=False, indent=2)
                    print(f"   ğŸ’¾ Updated classification saved to {self.classification_file}")
                except Exception as e:
                    print(f"   âš ï¸  Failed to save filtered classification: {e}")
            
            self.print_classification_summary(classification)
            
            translatable_files = classification.get("translatable_files", 0)
            if translatable_files == 0:
                print("ğŸ“‹ No files to translate, skipping translation steps...")
                
                # ç¿»è¨³ä¸è¦ã§ã‚‚ã‚³ãƒŸãƒƒãƒˆï¼†PRä½œæˆã¯å®Ÿè¡Œï¼ˆãƒãƒ¼ã‚¸ã‚³ãƒŸãƒƒãƒˆãªã©ï¼‰
                success = self.run_step(
                    "Create commit and PR",
                    ["python", "scripts/commit_and_pr.py", 
                     "--classification", str(self.classification_file)],
                    required=False
                )
                
                self.print_summary(success=True)
                return True
            
            print(f"ğŸ“ Found {translatable_files} files to translate, proceeding...")
            
            # Step 3: Translate files
            success = self.run_step(
                "Translate files",
                ["python", "scripts/translate_chunk.py", 
                 "--classification", str(self.classification_file),
                 "--mode", "all"],
                env_vars={"GEMINI_API_KEY": os.getenv("GEMINI_API_KEY", "")}
            )
            if not success:
                return False
            
            # Step 4: Post-process translations
            success = self.run_step(
                "Post-process translations",
                ["python", "scripts/postprocess.py",
                 "--classification", str(self.classification_file)]
            )
            if not success:
                return False
            
            # Step 5: Commit and create PR
            success = self.run_step(
                "Create commit and PR",
                ["python", "scripts/commit_and_pr.py",
                 "--classification", str(self.classification_file)],
                env_vars={
                    "GH_TOKEN": os.getenv("GH_TOKEN", ""),
                    "GITHUB_TOKEN": os.getenv("GITHUB_TOKEN", "")
                }
            )
            if not success:
                return False
            
            self.print_summary(success=True)
            return True
            
        except KeyboardInterrupt:
            print("\n\nğŸ’¥ Pipeline interrupted by user")
            self.print_summary(success=False)
            return False
        except Exception as e:
            print(f"\n\nğŸ’¥ Unexpected error: {e}")
            self.print_summary(success=False)
            return False


def main():
    parser = argparse.ArgumentParser(
        description="Run complete translation pipeline",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Run with specific commit hash
  python run_translation_pipeline.py --hash 90d107e2
  
  # Dry run (no actual translation/commit/PR)
  python run_translation_pipeline.py --hash 90d107e2 --dry-run
  
  # Run with latest upstream commit
  python run_translation_pipeline.py --hash HEAD
  
  # Development mode with filters
  python run_translation_pipeline.py --mode dev --hash HEAD --limit 5
  python run_translation_pipeline.py --mode dev --before abc1234 --paths docs/
        """
    )
    
    parser.add_argument(
        "--hash",
        default="HEAD",
        help="Target upstream commit hash (default: HEAD)"
    )
    
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="Dry run mode (skip translation, commit, and PR creation)"
    )
    
    parser.add_argument(
        "--mode",
        choices=["normal", "dev"],
        default="normal",
        help="Pipeline mode: normal (default) or dev (development with filters)"
    )
    
    # é–‹ç™ºãƒ¢ãƒ¼ãƒ‰å°‚ç”¨ã‚ªãƒ—ã‚·ãƒ§ãƒ³
    dev_group = parser.add_argument_group("development mode options")
    dev_group.add_argument(
        "--before",
        dest="before_commit",
        help="Process only files modified before this commit (dev mode only)"
    )
    
    dev_group.add_argument(
        "--limit",
        type=int,
        help="Limit number of files to process (dev mode only)"
    )
    
    dev_group.add_argument(
        "--paths",
        nargs="+",
        help="Process only files under these paths (dev mode only)"
    )
    
    args = parser.parse_args()
    
    # é–‹ç™ºãƒ¢ãƒ¼ãƒ‰å°‚ç”¨ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®æ¤œè¨¼
    if args.mode != "dev":
        dev_options = [args.before_commit, args.limit, args.paths]
        if any(opt is not None for opt in dev_options):
            print("âŒ Development mode options (--before, --limit, --paths) can only be used with --mode dev")
            sys.exit(1)
    
    # ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ç¢ºèª
    if not Path(".github/auto-translation").exists():
        print("âŒ This script must be run from the repository root")
        print("   Current directory should contain .github/auto-translation/")
        sys.exit(1)
    
    # ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ
    pipeline = TranslationPipeline(
        args.hash, 
        args.dry_run, 
        args.mode,
        args.before_commit,
        args.limit,
        args.paths
    )
    success = pipeline.run()
    
    sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()